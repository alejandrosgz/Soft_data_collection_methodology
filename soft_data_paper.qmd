---
#title: "Soft_data_paper"
#author: "Alejandro Sánchez Gómez"
bibliography: Paper_soft_data_collection.bib
highlight-style: zenburn
format: 
   #docx: 
   #  reference-doc: template.docx
   #  fig-align: center
   html: 
    toc: true
    toc-depth: 4
    editor: visual
---

```{r Used_libraries}
#| eval: true
#| echo: false
#| output: false

#Install packages if needed

#install.packages("readr")
#install.packages("tidyverse")
#install.packages("lubridate")
#install.packages("plotly")
#install.packages("patchwork")
#install.packages("gt")

library(readr)
library(sf)
library(tidyverse)
library(lubridate)
library(plotly)
library(patchwork)
library(gt)

```

```{r tables_format}
#| eval: true
#| echo: false
#| output: false

# https://www.anthonyschmidt.co/post/2020-06-03-making-apa-tables-with-gt/  #Source of this code
apa <- function(x){#, title = " ") {
  gt(x) %>%
    tab_options(
      table.border.top.color = "white",
      heading.title.font.size = px(16),
      table.font.size = px(14),
      column_labels.border.top.width = 3,
      column_labels.border.top.color = "black",
      column_labels.border.bottom.width = 3,
      column_labels.border.bottom.color = "black",
      table_body.border.bottom.color = "black",
      table.border.bottom.color = "white",
      table.width = pct(100),
      table.background.color = "white"
    ) %>%
    cols_align(align="center") %>%
    tab_style(
      style = list(
        cell_borders(
          sides = c("top", "bottom"),
          color = "white",
          weight = px(0.005)
        ),
        cell_text(
          align="center"
        ),
        cell_fill(color = "white", alpha = NULL)
      ),
      locations = cells_body(
        columns = everything(),
        rows = everything()
      )
    ) %>%
    #title setup
    #tab_header(
    #  title = html(title)  # html("<i>", title, "</i>")
    #) %>%
    opt_align_table_header(align = "left")
}

```

```{r baseflow_filter_function}
#| eval: true
#| echo: false
#| output: false

   baseflow_sep <- function(df=NA, Q="Q",
                            alpha=0.98,
                            BFIma=0.5,
                            method="two_param")
     {
     Q <- df[colnames(df) == Q][,1]
     Q[is.na(Q)] <- -9999.9
     R <- as.vector(matrix(data=NA, nrow=length(Q), ncol=1))
     B <- as.vector(matrix(data=NA, nrow=length(Q), ncol=1))
     R[1] <- 0
     B[1] <- 0
     
     #Eckhardt (2005): How to construct recursive digital filters for baseflow separation (Hydrological Processes, 19, 507-515)
                 for(i in 2:length(Q)){
                   if(Q[i] != -9999.9){
                     B[i] <- ((1-BFIma)*alpha * B[i-1] + (1-alpha)*BFIma* Q[i]) /
                       (1-alpha*BFIma)
                     if(B[i] > Q[i]){B[i] <-Q[i]} 
                     R[i] <- Q[i]-B[i]
                   } else {
                     R[i] <- NA
                     B[i] <- NA
                          }
                                     }
     return(data.frame(B,R))
     }

```

## Soft data collection for realistic hydrological modelling: a reproducible methodology developed in R for the Tagus River basin.

##### Alejandro Sánchez-Gómez*^1^, Katrin Bieger^2^, Silvia Martínez-Pérez^1^, Christoph Schürz^3^, Hendrik Rathjens^4^, Eugenio Molina-Navarro^1^.

####### ^1^ Department of Geology, Geography and Environment. University of Alcalá.

####### ^2^ Department of Ecoscience. Aarhus University.

####### ^3^ Department Computational Landscape Ecology. Helmholtz Centre for Environmental Research.

####### ^4^ Stone Environmental EU.

### Abstract

Models in hydrology have enriched the knowledge about this discipline, bringing to the scientific community new insights about hydrological questions. However, modelers should ensure that models reproduce the hydrological processes in a realistic way, which is not always the case. Obtaining satisfactory values of performance metrics for one variable (e.g., streamflow) is often considered enough to take a hydrological model as satisfactory, which might lead to a misrepresentation of the reality behind the model.

Soft data in hydrological modelling can be used to ensure that the main hydrological processes in a catchment are being realistically reproduced before starting a hard calibration. This process is known as soft calibration. Expert knowledge should guide it, being thus necessary to have available real data of some hydrological variables prior to carry out a soft calibration process.

This work presents a reproducible methodology for collecting soft data in a certain area and period. This methodology, developed in R, allows to estimate two key variables related to the hydrological processes in a catchment: the runoff coefficient (fraction of the precipitation volume that is converted to streamflow) and the baseflow index (fraction of groundwater contribution to the streamflow). As input data, gridded weather data and streamflow records are necessary to estimate both coefficients, and a baseflow filter is used for estimating the groundwater index.

The methodology has been tested in the upper sector of the Tagus River basin, addressing a multi-spatial hydrological assessment, estimating these two variables for 19 subbasins located in 5 different geological regions. Results obtained show relevant differences among regions, justifying the necessity of addressing such an evaluation.

Keywords: *Soft data*, *Soft calibration*, *Hydrological modelling*, *Hydrological processes*.

### 1. Introduction and objectives

Hydrological modelling has thrived in the last decades, and particularly during the last few years, mostly due to the increase of computational capacity and the availability of related open software [@singh_hydrologic_2018; @fu_review_2019] which usually comes with friendly guided-user interfaces. This has enriched the knowledge about this discipline, bringing to the scientific community new insights about hydrological questions and contributing to assess the hydrological risks that the humanity faces in a worldwide context of uncertainty. However, the fact of having readily available hydrological modelling tools also entails some risks: their users, from different backgrounds, might not have comprehensive knowledge of hydrological process, and thus they might rely on model outputs without the necessary critical thinking [@seibert_dialog_2002; @efstratiadis_one_2010].

Particularly, hydrological modelling applications often present results which are solely based on analyzing the performance of a certain metric (or metrics) for the calibrated variable (e.g., streamflow, evapotranspiration, etc.), without further discussing if the hydrological processes in the model that are yielding this metric value resemble the reality of the area that is being modelled [@bahremand_hess_2016; @acero_triana_beyond_2019]. The problem of equifinality within modelling techniques is well known: unrealistic parameter values can provide statistically satisfactory simulations [@muleta_model_2012; @molina-navarro_impact_2017]. Thus, when it comes to hydrological modelling, and particularly to catchment scale modelling, modelers should at least ensure that the main components in the water balance are properly represented and the contribution of the different streamflow components (surface, lateral and groundwater contribution) resembles what is expected in the analyzed catchment.

Some researchers have noticed about this issue in recent years, proposing the use of soft calibration techniques in order to guarantee realistic hydrological models [@arnold_hydrological_2015]. Soft calibration precisely consists of assessing model results against soft data, such us annual averages of the water balance components or the expected relative contribution of the different components of streamflow. Soft calibration might be followed by hard calibration, which would involve the comparison of simulated vs. observed time series of a certain variable. The works of Pfannerstill et al. [-@pfannerstill_how_2017] and Chawanda et al. [-@chawanda_mass_2020] are examples of successful experiences using soft data in hydrological modelling calibration.

Two key soft data variables are the runoff coefficient and the baseflow index [@blume_rainfallrunoff_2007]. Runoff coefficient is the fraction of precipitation volume that becomes streamflow. This variable it is not constant and depends on factor such as lithology, topography and the characteristics of the precipitation events. When considering a hydrological series, this coefficient can also be used to estimate the evapotranspiration, which is the main loss of the water balance in Mediterranean regions. Opposite to streamflow, evapotranspiration cannot be directly measured at basin scale. Thus, despite having some limitations, the runoff coefficient helps to understand the water balance of a certain basin. The limitations of this assumption (other than those derived from human activity) are related to climate variability, the storage of water in the aquifers or soils, groundwater interbasins connections, or groundwater that becomes streamflow downstream the gauging stations. Therefore, the groundwater systems should be known before validating the runoff coefficient, and enough long time series should be used to ensure that the storage of water is null and the time series climate is representative of the basin [i.e., more than 30 years of data in Mediterranean regions, @custodio_hidrologisubterranea_1983]. The estimation of this variable can be done if precipitation and flow data are available, the higher the resolution and reliability of the data the better. There are different methods to estimate this variable, with the SCS runoff curve number method of the USA Soil Conservation Service being the best known [@mockus_national_nodate]. Despite the availability of streamflow and precipitation data in Spain, works estimating this variable in the literature are limited to specific rainfall events, focusing on the factors that influence runoff generation [e.g., @kirkby_influence_2002; @rodriguez-blanco_rainfallrunoff_2012]. To the best of our knowledge, there is a lack of studies analyzing long time series that could be used for modeling purposes.

Baseflow is the component of the streamflow that does not immediately respond to the precipitation, but it is released from natural water storage systems such as glaciers or aquifers. Groundwater is the main source of baseflow in Mediterranean areas, and it is the responsible of maintain a permanent flow during low flow periods, i.e., during dry periods, which is particularly relevant regarding water quality and ecosystems functioning. It is therefore a key element of the water balance, which can suppose more than half of the total runoff [@jodar_groundwater_2017; @sanchez-gomez_streamflow_2023]. Groundwater depends on factors such as lithology, topography, climate or land use: the presence of aquifer rocks is needed for the existence of groundwater, and recharge processes are mainly determined by the topography, land covers, soil types and the characteristics of the precipitation events. The baseflow index indicates the fraction of the total streamflow that comes from groundwater systems. This variable can be estimated trough different methods, such as using hydrological models [@samper_hydrological_2015], mass-balance methods with chemical tracers [@ortega_using_2015], or applying numerical or graphical methods to streamflow records to perform a separation of its components (baseflow and direct runoff). Regarding the latter, different digital filters that perform this separation have been developed, allowing to estimate the baseflow index with only streamflow data [@kang_baseflow_2022].

The values of runoff coefficient or baseflow index for a certain catchment can be sometimes found in the literature, since previous hydrological studies might exist. Some works might also provide expected values for certain regions, depending on their climate and/or their hydrogeological characteristics [e.g., @custodio_hidrologisubterranea_1983]. However, an ideal soft calibration procedure would involve obtaining runoff coefficient and baseflow index estimates for the catchment that is being analyzed and the period that is being modeled. This would help guaranteeing that the model is simulating the hydrological processes in a realistic manner, providing also a more robust starting point for the subsequent hard calibration. Thus, to avoid the issue of creating unrealistic hydrological models above discussed, there is a need to develop procedures and methodologies that facilitate soft data variables for a certain area and period, thus encouraging modellers to address soft calibration before hard calibration.

The main goal of this work is to present a reproducible methodology developed in R for collecting soft data in a certain area and time period, particularly the runoff coefficient and the baseflow index. To prove the usefulness of this work, a study case for the Tagus River basin (Spain) is also presented, since the research team is developing a high-detailed hydrological model with SWAT+ for its upper sector [@sanchez-gomez_innovative_2022]. Furthermore, this study case shows how this methodology allows to obtain different values of these two coefficients in different geological regions within the basin, which might be convenient since addressing a zonal calibration depending on the geological properties turns into a more robust and realistic model [@sanchez-gomez_optimization_2022]. The proposed methodology uses precipitation and streamflow data to derive those two coefficients, together with expert knowledge: gridded precipitation data and streamflow from gauging stations were used to calculate the runoff coefficient for different subbasins in natural regime, while expert knowledge guided the application of a baseflow filter function to estimate the baseflow index from streamflow data.

The following sections of the manuscript describe the work done in detail, presenting an R script that could be applied in any region with gridded precipitation and streamflow data. Besides, the study case presented in the Tagus River basin, has in turn served to address a deep analysis of some of its hydrological processes, gaining knowledge about this region.

### 2. Study area

The Tagus River (@fig-location) is the longest in the Iberian Peninsula, and its basin is the most populated. Water resources in this basin are scarce considering the high demand of water, and it is expected that climate change will exacerbate this situation. In addition, a water transfer system extract water from the headwaters of the Tagus River to the southeast of Spain to supply irrigation and human consumption demands. Thus, realistic hydrological modelling of this catchment is of utmost importance in order to guarantee reliable future assessments of, for example, climate change impacts.

The upper sector of the Tagus River basin (3,388 km²) covers around 47% of the extension of the entire basin. This sector is delimited by three mountain ranges: the Central System in the north, the Iberian System in the east, and the Toledo Mountains in the south. Altitude ranges from 2,400 m.a.s.l. in some peaks of the Central System to 360 m.a.s.l. in Talavera de la Reina (Toledo), the outlet of the upper basin. The upper sector of the basin (@fig-location) is characterized by a continental Mediterranean climate, which varies depending on factors such as altitude, proximity to the ocean and latitude. Chazarra et al. [-@chazarra_bernabe_mapas_2018] classified this sector as temperate (C) and dry (B) following the Köppen-Geiger climate classification for the period 1980-2010. The mean precipitation for this period was around 550 mm, with values higher than 1.400 mm in the Central System, and lower than 400 mm in the driest areas of the southern sector. The mean temperature is around 12ºC, which varies between 13ºC in the east, 17ºC in the west and 8ºC to 10ºC in the Central System [@chazarra_bernabe_mapas_2018]. The average precipitation and water yield of the basin has been reduced in the last decades, which could be attributed to the impacts of climate change [@garcia_serie_2017].

Natural vegetation and agricultural lands are the main land covers of the area, occupying around 48% and 47%, respectively of the total area, being cereals the dominant crop. Urban use covers around 3% of the total area, being approximately 8 million inhabitants in this sector of the basin. Therefore, relevant water demands are located in this area, with noticeable environmental and social implications.

In this sector of the basin, the confluence of different mountain systems with different bedrocks has originated a heterogeneous geological configuration, which gives rise to differences in the main hydrological processes. Direct runoff is expected to predominate in the Central System and in the Toledo mountains, which are conformed by igneous and metamorphic rocks with low permeability. In contrast, the carbonate rocks of the Iberian System configure important aquifers, thus being the baseflow index more relevant. The sedimentary deposits of the basin also have varying hydrological properties, with Tertiary rocks and Quaternary alluvial sediments with high permeability that are relevant aquifers in some regions, while there is also detrital and evaporitic materials with low permeability. This basin, therefore, is a complex system which requires a comprehensive methodology to be modeled. This modelling process would benefit from a soft calibration phase towards the realistic simulation of the different geological sector. For such a purpose, collection of soft data is needed, and the methodology followed to achieve this task is described and discussed below.

![Study area location, lithology, permeability and selected basins.](figs/Studied_basinss.png){#fig-location}

### 3. Methodology

#### 3.1. Subbasins and time series selection

The objective of the methodology presented in this manuscript is to collect and derive soft data (runoff and baseflow coefficients) in different geological regions of the upper sector of the Tagus River basin with varying permeability, thus gaining knowledge about the main hydrological processes in each region that would guarantee a realistic soft calibration of a model under development. For this purpose, several subbasins have been selected considering various factors (@fig-location). The availability of updated streamflow records was the first selection factor. To characterize the runoff and baseflow coefficients of a certain catchment, the longer the time series the better, being advisable a minimum time series of 30 years [@custodio_hidrologisubterranea_1983]. However, in this study case the plan is to calibrate the model between 2010 and 2018, thus in order to simulate it in a realistic manner, the coefficients for that period had to be derived. Besides, despite it is not too large, this period has enough climatic variability to be considered representative of the global climate of the basin, having dry, wet, and medium years (@fig-pcp_plot), so results obtained during the soft data extraction might also serve to gain hydrological knowledge of the catchment. The current effect of climate change on this basin has to be taken into account as well: the precipitation is being reduced and the temperature is rising (i.e., comparing the time series 1960-2018 and 2000-2018, mean annual temperature has increased 0.5ºC and annual precipitation has been reduced by 7%). Thus, a longer period may not be representative of the current situation.

![Modeled basin annual and average precipitation (1951-2018) and selected period (in blue).](figs/precipitation_tagus.tiff){#fig-pcp_plot}

Since different geological regions are object of study, lithology was the second factor considered for selecting the subbasins. Four different geological zones were defined according to the permeability of the basin [@del_pozo_gomez_mapa_2009], and at least three basins representative of each of these regions were selected (@fig-location). Five basins with a mixed lithology were also chosen, in order to characterize the hydrological behaviour in heterogeneous regions (MIX). The geological regions defined were: an impervious region (IMP), with by metamorphic and igneous impervious rocks; a high and medium permeability carbonate region (CRB), a high permeability detrital region (DTAL), conformed by Tertiary sedimentary rocks and Quaternary sediments; and a low permeability detrital region (DTBJ), conformed by detrital and evaporitic materials (i.e., marls, gypsum). Unfortunately, there is not geologically homogeneous gauged subbasins within the low permeability detrital region, so subbasins with abundance of these materials were selected as representative, despite being mixed with other materials too.

For an accurate estimation of the runoff and baseflow coefficient, subbasins in natural regime were selected, thus without relevant reservoirs or water withdrawals, being this the last selection criterion.

Streamflow gauged data was analyzed in each subbasin to ensure its reliability, both with graphical and statistical methods. Information about the selected subbasins and their available streamflow data can be found in Appendix I. Some of the subbasins (subbasins 2, 6 and 14) did not have data for the entire time series, and therefore the coefficients have been calculated for the years with complete gauging data. Verify the data availability for the entire period is recommended, as the used source of streamflow data does not warn about missing data, which can lead to incorrect results.

#### 3.2. Input data and basins delineation

The presented methodology requires some input data and also some files that have to be created by the user. In this section, the input data used in this work and the methodology followed to create the files are described.

Two main data sets have been used in this work, one for weather data and one for streamflow data, both at daily scale. Precipitation and temperature data were obtained from the Spanish Meteorological Agency (AEMET) grid (5 km resolution, @garcia_serie_2017), with available data for the entire Spanish territory from 1951 to 2019. The purpose for using this input is that allows to know accurately the amount of renewable water resources in each of the studied subbasins. Streamflow data was collected from the CEDEX streamflow gauging stations yearly report [@cedex_anuario_2021], which contains daily measurements of the gauging stations located in Spain and grouped by hydrographic demarcation (having downloaded those located within the Tagus River basin, *afliq.csv*).

After verifying that the selected gauging stations for each subbasin had enough and reliable data, the first step was to delineate the subbasins, i.e., the drainage area for each of the gauging stations. For this purpose, a digital elevation model was obtained from the National Geographic Institute [@ign_centro_2010], and the GRASS module [@neteler_grass_2012] in QGIS [version 3.22, @qgis_development_team_qgis_2022] was used. For the subbasins´ delineation, the *r.watershed* command was used for creating from the digital elevation model a *Drainage direction* and a *Number of cells that drain through each cell* raster, using as attributes a *Minimum size of exterior watershed* of 10000 m² and *Enabling single flow direction*. With the *r.water.outlet* command, using the drainage direction raster generated and indicating the coordinates of the gauging stations (outlets of the subbasins), the drainage area was delineated for each subbasin. The command *r.to.vect* was used to convert the generated raster into vector format (using the *Smoooth corners of areas features* option), and all the generated basins were merged using the *Merge vector layers* QGIS command. The attribute table of this vector layer can be edited to include factors for grouping basins, as in this case has been done with the geological region. Then, the *sf* and *dplyr* packages [@pebesma_simple_2018; @wickham_tidyverse_2022,] have been used to calculate the area of the subbasins, and a new field with the identifier of the gauging station for each subbasin have been added, finally creating the file *1_basins_file.csv*.

```{r}
#| echo: true
#| eval: false

# Input data: Shapefile with the delineated subbasins 
subbasins <- read_sf("used_files/GIS/Shapefiles/basins_studied.shp") %>% arrange(., id)
# Changing column names
subbasins_csv <- subbasins %>% rename(Basin_ID = id) %>% 
#Calculating area
mutate(area = st_area(.)) %>% 
# Introducing the gauging stations codes (Manually)
mutate(gauging_code = c(3231, 3049, 3211, 3001, 3045, 3040,
       3249, 3172, 3193, 3251, 3186, 3173, 3164, 3165, 3212, 
       3268, 3237, 3030, 3060)) %>% 
# Spatial data is no longer necessary
st_drop_geometry(.) %>% 
# Ordering table
.[,c("Basin", "Basin_ID", "area", "gauging_code", "region")]
write.csv(x =subbasins_csv, file = "used_files/Created_csv/1_basins_file.csv", row.names = F)
```

In order to estimate the precipitation and temperature for each subbasin, it was necessary to know which points of the weather grids are located within. A grid vector layer was created with all the weather points located in the study area, and those points located inside a 1 km buffer performed for each of the subbasins were identified. The buffer and clipping processes were performed with sf package. The buffer distance depends on the data resolution, and in this case it has been considered appropriated. A csv file containing the identifier of each grid point located in the subbasins (also indicating in which subbasin it is) has been created and saved as *2_ids_stations_file.csv*. Note that in this case the identifiers and location of precipitation and temperature points of the grid matched, thus being only necessary to have one file for both variables.

```{r}
#| echo: true
#| eval: false

# Gauging points
pcp_points <- read_sf("used_files/GIS/Shapefiles/grid_tagus.shp")
# Subbasins 
subbasins <- read_sf("used_files/GIS/Shapefiles/basins_studied.shp") %>% arrange(., id)
# Buffer created for subbasins (1 km distance)
subbasins_buffer <- st_buffer(subbasins, dist = 1000) 
# Clipping grid points with the subbasins buffer
grid_points_clip <- st_intersection(pcp_points, subbasins_buffer[, c("id", "Basin", "geometry")])
# Spatial data is no longer necessary, and a variable is renamed before saving
grid_points_clip_csv <- grid_points_clip %>% st_drop_geometry(.) %>% rename(Basin_ID = id)
write.csv(x = grid_points_clip_csv, file = "used_files/Created_csv/2_ids_stations_file.csv", row.names = F)
```

With these two csv files (created from the subbasins and weather grid vectorial layers) the methodology can be carried out. Two more csv files will be created with the results of the baseflow index assessment, as explained in the respective section (3.4). Examples of these files are available for the reader in order to allow reproducibility of the work (see Data availability section). From this point on, all the work has been developed from R-Studio [@rstudio_team_rstudio_2020] using different libraries [@wickham_readr_2022; @pebesma_simple_2018, @wickham_tidyverse_2022; @spinu_lubridate_2023; @sievert_plotly_2022; @pedersen_patchwork_2022; @iannone_gt_2022].

```{r used_files}
#| eval: true
#| echo: true
#| output: false

# File with basins data
basins_file <- read.csv("used_files/Created_csv/1_basins_file.csv") 
# File with grid points identifiers 
pcp_grid_points <-  read.csv("used_files/Created_csv/2_ids_stations_file.csv") 
# File with gauging data
gauging_data_tagus <- read.csv("used_files/Data/Gauging_data/afliq.csv", sep = ";") %>% 
  tibble(.,"cod" = indroea, "date" = fecha, "obs_flow" = caudal) %>% 
  .[, c("cod", "date", "obs_flow")] %>% mutate(date = dmy(date))
```

#### 3.3. Runoff coefficient calculation

For the calculation of the runoff coefficient, precipitation, temperature and streamflow data were used. The csv files created in section 3.2 were used for this purpose, as the area calculated and the identifiers of the gauging stations and the grid points located within the buffer of each subbasin were necessary

From all the gauging stations inside the Tagus River basin, the ones used for this work were filtered using their identifier. Then, gauged data was aggregated from daily values (m³/s) to annual contribution (mm/year) using the basins area. As mentioned above, basins 2, 6 and 14, despite not having data since 2010, were selected because they were in natural regime, being other basins representative of their lithology regulated. In this way, an annual runoff value (mm) was obtained for each of the studied basins using the code below.

```{r Runoff_calculation}
#| eval: true
#| echo: true
#| output: false

#### Runoff calculation ####

# Gauging stations codes
cods <- basins_file$gauging_code 
# Drainage areas
areas <- basins_file$area 
obs_anual <-  list() 
for(i in 1:length(cods)){
  gaug_st <- filter(gauging_data_tagus, cod == cods[i],(year(date) %in% 2010:2018))
  # Average annual flow (m³/s)
  caud_anual <- gaug_st[,c("date", "obs_flow")] %>% group_by(year = year(date)) %>% 
    summarise(., obs_m3 = mean(obs_flow)) %>% 
  # Annual contribution (mm/year) 
  mutate(obs_mm = (obs_m3*86400*365*1000)/ (areas[i])) %>% 
   cbind(bas = i) %>% .[,c("bas", "year", "obs_mm")]
  # Gauged data for all the basins
  obs_anual[[i]] <- caud_anual 
}
# Fixing basins 
# Basins 2 and 6 have data only from October 2010. The first row (2010) is therefore eliminated
obs_anual[[2]] <- obs_anual[[2]][-1,]
obs_anual[[6]] <- obs_anual[[6]][-1,]
# Basin 14 have data only from July 2011. The first row (2011) is therefore eliminated
obs_anual[[14]] <- obs_anual[[14]][-1,]
```

Daily precipitation data (mm) was aggregated to calculate the annual precipitation (mm/year) for each grid point and then the average precipitation for each subbasin. Despite other methods (i.e., interpolation) could estimate the average precipitation in a more accurate way, considering the resolution of the used weather grids this approximation has been considered appropriate. The average maximum, minimum and mean temperature was calculated in a similar way [but from the AEMET maximum and minimum temperature grid, @garcia_serie_2017] for each year in all the subbasins to reinforce the discussion of the results, as this variable directly affects the evapotranspiration and therefore to the runoff coefficient.

```{r Precipitation_calculation}
#| eval: true
#| echo: true
#| output: false

# Precipitation points files path
path <- "used_files/Data/Climate_data_extracted/pcp_spain/"
# File with grid points identifiers 
pcp_grid_points <-  read.csv("used_files/Created_csv/2_ids_stations_file.csv")
# Creating dates for the entire period (1951-2019)
init_date <- as.Date("1951-01-01")
end_date <- as.Date("2019-12-31")
dates <- seq(init_date, end_date, 1) 
# Annual precipitation calculation
pcp_bas_list <- list() 
# i --> Basin ID
for(i in 1:length(unique(pcp_grid_points$Basin_ID))){  
  # Precipitations points inside Basin i
  filt_st <- filter(pcp_grid_points, Basin_ID == i) 
  stations <- filt_st[,1]
  pcps_sts <- c()
  # n --> Precipitation point identifier
  for(n in 1:length(stations)){
    # Total precipitation for each year in each point   
    st_dat <- read_table(paste(path, stations[n], "_PCP.txt", sep = ""), skip = 1, col_names = F) %>% 
      mutate(date = ymd(dates), pcp = X1) %>% .[,c("date", "pcp")] %>% group_by(year(date)) %>% 
      summarise(pcp_year = sum(pcp)) 
      colnames(st_dat) <- c("year", "pcp")
    # Filtering with the study period
    pcp_st <- filter(st_dat, year %in% 2010:2018) %>% .[,"pcp"] 
    pcps_sts <- tibble(pcps_sts, pcp_st, .name_repair = "unique") 
  }
  # Basin average precipitation from all the precipitation points within  
  pcp_bas <- pcps_sts %>% apply(., 1, mean) %>% cbind(year = c(2010:2018)) %>% 
    tibble(year = .[,"year"], pcp_y = .[,"."]) %>% .[,c("year", "pcp_y")]  
  pcp_bas_list[[i]] <- pcp_bas[, "pcp_y"] %>% cbind(year = c(2010:2018), bas = i)
}
```

```{r Temperature_calculation}
#| eval: true
#| echo: false
#| output: false

   # Temperature points files path
   path <- "used_files/Data/Climate_data_extracted/tmp_spain/" 
   # Creating dates for the entire period (1951-2019)
   init_date <- as.Date("1951-01-01")
   end_date <- as.Date("2019-12-31")
   dates <- seq(init_date, end_date, 1) # A sequence of dates for the entire serie is created
   tmp_grid_points <-  read.csv("used_files/Created_csv/2_ids_stations_file.csv") %>% arrange(., Basin_ID)  # File with IDs, names, and location of the grid points, and subbasins data  
   
   # Loop for calculating the temperature of each basin trough the average of the annual temperature (Max, min, mean) for each station within the basin
   tmp_bas_list <- list() #empty list 
   for(i in 1:length(unique(tmp_grid_points$Basin_ID))){  # i --> Basin ID
     filt_st_t <- filter(tmp_grid_points, Basin_ID == i)
     stations_t <- filt_st_t[,1]
     tmps <- c()
     for(n in 1:length(stations_t)){   # n --> Weather stations identifier within each basin
       st_dat_t <- read.csv(paste(path, stations_t[n], "_TMP.txt", sep = ""), skip = 1,header = F) %>% 
         mutate(date = ymd(dates), tmp_M = V1, tmp_m = V2) %>% .[,c("date", "tmp_M", "tmp_m")] %>% group_by(year(date)) %>% 
         summarise(tmp_M = mean(tmp_M),tmp_m = mean(tmp_m), tmp_mean = (tmp_M + tmp_m) /2) %>% .[,c(1,3,2,4)]
       colnames(st_dat_t) <- c("Year", "Average minimum temperature", "Average maximum temperature", "Mean temperature")
       
       tmp_mins <- c()
       tmp_min <- filter(st_dat_t, Year %in% 2010:2018) %>% .[,"Average minimum temperature"]
       tmp_mins <- tibble(tmp_mins, tmp_min, .name_repair = "unique")    # Minimum temperature for each station 
       tmp_maxs <- c()
       tmp_max <- filter(st_dat_t, Year %in% 2010:2018) %>% .[,"Average maximum temperature"]
       tmp_maxs <- tibble(tmp_maxs, tmp_max, .name_repair = "unique")    # Maximum temperature for each station 
       tmp_means <- c()
       tmp_mean <- filter(st_dat_t, Year %in% 2010:2018) %>% .[,"Mean temperature"]
       tmp_means <- tibble(tmp_means, tmp_mean, .name_repair = "unique") # Mean temperature for each station 
     }
     tmp_bas_list[[i]] <- tibble(Year = c(2010:2018), 
                                 Tmp_min = apply(tmp_mins, 1, mean),   # Minimun temperature for each basin
                                 Tmp_Max = apply(tmp_maxs, 1, mean),   # Maximun temperature for each basin
                                 Tmp_mean = apply(tmp_means, 1, mean)) # Mean temperature for each basin
      }
      
      #With this data, the average values for the entire period has been calculated for each subbasins
      # As subbasins 2, 6 and 14 only have gauged data from 2012-2018, average temperature has been calculated for this period.
   
      tmp_bas_list[[2]] <- tmp_bas_list[[2]][-c(1),]   # Shortening data for Basin 2
      tmp_bas_list[[6]] <- tmp_bas_list[[6]][-c(1),]   # Shortening data for Basin 6
      tmp_bas_list[[14]] <- tmp_bas_list[[14]][-c(1:2),] # Shortening data for Basin 14
   
      # Loop for calculating the average minimun, maximun and mean temperature for all the subbasins
      mins <- c()
      maxs <- c()
      means <- c()
      for(i in 1:length(tmp_bas_list)){
       min <- mean(tmp_bas_list[[i]][[2]] )
       mins <- c(mins, min)
       max <- mean(tmp_bas_list[[i]][[3]] )
       maxs <- c(maxs, max)
       mean <- mean(tmp_bas_list[[i]][[4]] )
       means <- c(means, mean)
      }
      
      temperature_tibb <- tibble(Basin_ID = c(1:length(tmp_bas_list)), mins, maxs, means)
```

The runoff coefficient was calculated for each year from the runoff and precipitation values calculated with this process, obtaining an estimation of the fraction of water that is converted into streamflow and the fraction of water that is evapotranspirated. The average runoff coefficient value for all the period for each basin and geological region was evaluated, and the annual variation for each basin taking into account the precipitation and temperature can be also generated with this code for further assessments.

```{r Runoff_rate_calculation}
#| eval: true
#| echo: true
#| output: false
 
   anual_runoff_rate <- list() 
   basin_runoff_rate <- list() 
   basin_runoff_rates <- c()   
   for(i in 1:length(pcp_bas_list)){
     # List with the annual values
     anual_runoff_rate[[i]] <- obs_anual[[i]] %>% left_join(pcp_bas_list[[i]], by = "year") %>% 
                               mutate(Basin_ID = bas.x, Year = year, Pcp = pcp_y, 
                                      Runoff = obs_mm, Runoff_rt = Runoff/Pcp) %>% 
                               .[,c("Basin_ID", "Year", "Pcp", "Runoff", "Runoff_rt")] 
     # Average precipitatiOn, runoff and runoff coefficient values for the entire period
     basin_runoff_rate[[i]] <- anual_runoff_rate[[i]] %>% summarise(Basin_ID = mean(Basin_ID), 
                                Mean_pcp = mean(Pcp), Mean_runoff = mean(Runoff), 
                                Runoff_rate = mean(Runoff_rt), Max_runoff_rate = max(Runoff_rt), 
                                min_runoff_rate = min(Runoff_rt), Runoff_rate_sd = sd(Runoff_rt)) %>% 
                                unlist(.) 
     # Merge the average list values
     basin_runoff_rates <- basin_runoff_rates %>% rbind(basin_runoff_rate[[i]]) 
   }
   
   # Table with the obtained values for each basin
   tib_basin_runoff_rates <-  basin_runoff_rates%>% data.frame(.) %>% tibble(.) 
   tib_basin_runoff_rates <- tib_basin_runoff_rates%>% left_join(., basins_file[,c(1:2,5)], "Basin_ID") %>% 
                             .[,c("region", "Basin_ID" , "Basin", "Mean_pcp", "Mean_runoff", 
                                  "Runoff_rate", "Runoff_rate_sd", "Max_runoff_rate", "min_runoff_rate")] 
   # Table with the obtained values for regions
   tib_region_runoff_rates <- tib_basin_runoff_rates %>% group_by(region) %>% summarise(Mean_pcp = mean(Mean_pcp),
                              Mean_runoff = mean(Mean_runoff), Mean_runoffrt = mean(Runoff_rate),
                              Runoffrt_sd = mean(Runoff_rate_sd)) 
```

#### 3.4. Baseflow contribution estimation

In this work, the baseflow contribution has been calculated for the 19 selected subbasins using a baseflow filter function based on the equation proposed by [@eckhardt_how_2005], @eq-bf_filter. This equation calculates the baseflow for a day (b~k~) based on the two filter parameters (*alpha* and *BFImax*) and the streamflow of this day (y~k~).

$$ b_{k} = \frac{(1 - BFImax) * alpha * b_{k-1} + (1 - alpha) * BFImax * y_{k}} { 1 - alpha * BFImax} $$ {#eq-bf_filter}

*BFImax* is the maximum value of baseflow contribution expected for one day, and *alpha* is defined by [@eckhardt_how_2005] as a recession constant in the form:

$$ b_{k} = alpha * b_{k-1} $$ {#eq-alpha_rec_constant}

This might be slightly confusing since the literature [@maillet_essais_1905; @zhu_estimation_2010] usually represents the groundwater recession constant as α, like in @eq-gw_recession, where Q~0~ is the streamflow at the beginning of the recession and Q~t~ is the streamflow in the day t:

$$  Q_{t} = Q_{0} * e^{-α * t} $$ {#eq-gw_recession}

@eq-gw_recession can be converted to a linear equation ($y = mx + b$) using logarithms, where the intercept is the streamflow at the beginning of the recession and the slope is the groundwater recession constant (α):

$$ ln(Q_{t}) = ln(Q_{0})-α * t$$ {#eq-gw_linear_recession}

Considering @eq-alpha_rec_constant and @eq-gw_recession when $t = 1$, and making the assumption that during the recession all the flow is baseflow, it can be deduced that:

$$alpha = e^{-α}$$ {#eq-alpha_conversion}

The effects of these parameters on the baseflow estimation have been assessed to know their importance (@fig-parameters_effect). Both parameters have been proved in a wide range of values, and both are noticeable sensitive to the baseflow component separation. *BFImax* affects directly to the amount of baseflow that the filter estimates, as it is the maximum percentage expected, being the estimated baseflow line directly proportional to the *BFImax* values. *alpha* controls the immediacy of the baseflow response to episodes of flood or recession, being higher values of *alpha* less sensitive to those changes. It also influences on the amount of baseflow that is calculated, as high values of *alpha* prevent the baseflow estimated to be high. Both parameters are closely related to the lithology of a basin: basins with aquifer systems will have a higher contribution of groundwater to the streamflow than impervious basins, and therefore should have higher *BFImax* values; and permeable basins with higher aquifer-river connectivity (i.e., sandy aquifers) will be more sensitive to recharge-discharge episodes than basins with less permeable substrates (e.g., clayey lithologies aquifers) and therefore *alpha* value, which is related to the transmissivity, will be lower. Then, the properties of a basin must be taken into account before setting these parameters of the baseflow filter, as other authors reported [@kang_baseflow_2022].

![Parameters effect on the baseflow filter calculation.](figs/parameters_effect_plot.png){#fig-parameters_effect}

In order to provide realistic values to the baseflow filter, *alpha* has been estimated for each basin, and *BFImax* has been established considering the recommended ranges depending on the basin properties [@eckhardt_how_2005], expert knowledge and ensuring that the baseflow separation obtained is realistic through its graphical representation.

For the estimation of *alpha*, the groundwater recession constant (α) was calculated using the function attributed to Maillet [-@maillet_essais_1905], @eq-gw_recession. This equation assumes that the aquifer behaves like a reservoir which releases water following a linear function, and although this assumption is not strictly correct, it is considered a valid and convenient simplification [@wittenberg_baseflow_1999]. In this way, from daily streamflow records, the groundwater recession constant can be estimated through a linear regression of the recession curve, where the slope is this constant. The groundwater recession curve was identified for three representative streamflow peaks in each subbasin. These peaks were selected considering aspects such as their magnitude, duration and shape (@fig-recession_curve). A linear regression of the neperian logarithm of the streamflow on the recession time (@fig-recession_curve) was performed using the *stats::lm()* function, obtaining a linear equation similar to @eq-gw_recession. The initial point of the recession curve has been selected when the direct runoff ceased and the baseflow took maximum values. Despite the ambiguity in determining the beginning and the end of the recession curve [@blume_rainfallrunoff_2007], representing the streamflow with a semi logarithmic axis can help to determine these points, since the recession curve conforms approximately to a straight line (@fig-recession_curve). A minimum of 10 days of recession curve, which ensures that the linearity of the equation is a good approximation [@chapman_comparison_1999], and a minimum value of determination coefficient 0.8 were used as criteria for calculating the groundwater recession constant. Despite a recession curve without any precipitation is desirable for adjusting the linear regression, it was not always possible to comply with this condition due to the data itself. Following this methodology, the linear regression equation slope (α) has been calculated for deriving the *alpha* parameter @eq-alpha_conversion, as showed below.

```{r Recession_constant_estimation}
#| eval: true
#| echo: true
#| output: false
 
   # Performed for subbasin 4, Peralejo
   peralejo <- gauging_data_tagus %>% filter(., cod == 3001) %>% filter(year(date) > 2009)
   # Performed for the Peak 3
   peak_3_peralejo <- peralejo[c(3360:3475),] 
   # Recession curve definition and regression
   recession_curve <- tibble(flow = peak_3_peralejo$obs_flow[55:90], 
                      day = seq(1, length(peak_3_peralejo$date[55:90]), 1))
   reg_pk3 <- lm(log(recession_curve$flow)~recession_curve$day)
   
   Recession_constant <-  reg_pk3[[1]][[2]]
   Intercept <- reg_pk3[[1]][[1]]
   
   #Recession constant for the Peak 3 is -0.024 and 1.77 is the intercept. 
   # alpha value equals to e^(-0.024) = 0.977
```

![Peaks selection, groundwater recession curve identification and linear adjustment performed for subbasin 4.](figs/peaks_selection_adjustment.png){#fig-recession_curve}

Three *alpha* values were calculated with this method for each basin, having a range of values to introduce in the baseflow filter function. For *BFImax*, the recommended values are around 0.8 for perennial streams with porous aquifers, around 0.5 for ephemeral streams with porous aquifers, and around 0.25 for perennial streams with hard rock aquifers [@eckhardt_how_2005]. However, these values leaded in some cases to an overestimation of the baseflow and to unreal components separation, then these values were adjusted in each case considering the properties of each basin and the expert knowledge. For each basin, different *alpha* and *BFImax* values were adjusted to obtain a realistic baseflow component separation for three representative peaks, and once this was reached, the average contribution of the baseflow to the streamflow (Bf~c~) was calculated with @eq-bf_contribution, where n is the number of days for which the filter is applied, bf~k~ is the baseflow contribution for the day k and rn~k~ is the runoff contribution for the day k.

$$ Bf_c =  \frac {\sum_{1}^{n} bf_k}  {\sum_{1}^{n} (bf_k + rn_k)}   $$ {#eq-bf_contribution}

The following example shows for one subbasin how the filter has been used. This example is represented in @fig-bfsep_example, where daily precipitation has been represented above the baselow estimation in order to help to perform the streamflow components separation.

```{r Baseflow_filter_example}
#| eval: false
#| echo: true

   # Example of baseflow filter application to Subbasin 4
   # Mean Alpha obtained : 0.982, Max 0.986, Min 0.976
   peralejo_flow <-  gauging_data_tagus %>% filter(., cod == 3001) %>% 
                     filter(year(date) %in% 2010:2018) %>% 
                     mutate(day = seq(1, length(date), 1))
   peralejo_pcp <- pcpday_bas4 %>% mutate(day = seq(1, length  (pcpday_bas4$date)))
   # Joining pcp and streamflow data by date and creating data frame
   peralejo_all <- peralejo_flow %>% left_join(peralejo_pcp, "date") %>% 
                  as.data.frame(.[,c(1,2,4,3,5)])
   #Filter parameters
   alfa <- 0.982
   bfi_max <- 0.5
   # Running the filter
   bfsep <- baseflow_sep(df = peralejo_all, 
                         Q = "obs_flow", 
                         alpha = alfa, 
                         BFIma =bfi_max, 
                         method = "two_param")
   bfsep_tibble <- peralejo_all %>% mutate(baseflow = bfsep$B, #baseflow
                                            runoff = bfsep$R)   #runoff
   # Calculating the streamflow contribution
   sum(bfsep_tibble$baseflow) / (sum(bfsep_tibble$baseflow)+sum(bfsep_tibble$runoff))
```

![Baseflow separation example performed for the peak 2 of the subbasin 4.](figs/subb_4_bfsep.png){#fig-bfsep_example}

The estimation of baseflow contribution has been performed through a more complex and subjective method than the runoff coefficient calculation. The use of a baseflow filter program allows to make the hydrograph components division in an easy way, but also can leads to unrealistic results, since some key factors are not automatically taken into account by the filter and thus need expert knowledge supervision. The filter used, based on two parameters, is relatively simple but also allows to take into account factors such as porosity and transmissivity when separating the hydrograph, therefore being able to reproduce the groundwater systems behavior. As the *alpha* and baseflow index estimation has been performed through a manual process, the obtained values have been saved on the csv files *3_alpha_estimation.csv* and *4_groundwater_results.csv*, respectively.

### 4. Results and discussion

#### 4.1. Runoff coefficient values

The followed methodology for calculating the runoff coefficient ratio can be used to assess the fraction of renewable water resources within a basin that is converted into runoff. Runoff coefficient has been calculated for 19 subbasins of the upper sector of the Tagus River basin for the period 2010-2018 (with some exceptions for subbasins 2, 6 and 14), both average and annual values, and the obtained values have been compared considering the precipitation, temperature and geological regions. Appendix II contains the mean, maximum and minimum runoff coefficient values obtained for each basin, and the mean precipitation and temperature for the time series.

The obtained values (showed in Appendix II) highlight the importance of carrying out this previous assessment when performing the calibration of a hydrological model. A wide range of values for the mean runoff coefficient has been obtained in different subbasins of the Tagus River basin (from 47% in the subbasin 2 to 2% in the subbasin 13). Within the subbasins themselves, the runoff coefficient also varies greatly from year to year (e.g., the maximum value for Basin 10 is 16 times higher than the minimum value, Appendix II). As expected, runoff coefficient seems to be related with the mean precipitation (less precipitation led to lower values of runoff coefficient), the mean temperature (higher temperatures lead to more evapotranspiration rate and in turn less runoff coefficient), and also to the geological region (Appendix II). However, this it is not always the case, being some years in some subbasins when runoff coefficient seems to respond also to other factors. A further comprehensive analysis about the yearly runoff coefficient variation taking into account different variables (precipitation, temperature, slope, surface, main land cover or lithology, etc.) could be performed from this data, but that is out of the scope of this work. @tbl-reg_runoff_rates summarizes to region scale the obtained average runoff coefficient presented in Appendix II.

```{r Runoff_rate_regions}
#| eval: true
#| echo: false
#| output: true
#| label: tbl-reg_runoff_rates
#| tbl-cap: Geological regions runoff coefficients. Average, minimum and maximum average runoff coefficient values for the representative subbasins


 runoff_tmp_annual_list <- list() #For each basin, a list for the annual values
      for(i in 1:length(tmp_bas_list)){
        tmp <- tibble(tmp_bas_list[[i]])
        runoff <- tibble(anual_runoff_rate[[i]])
        tibb_merge <- left_join(tmp, runoff, "Year") %>% left_join(., basins_file[,c(1,2,5)], "Basin_ID") %>% .[,c(10,5,9,1,4,2,3,6,8)]
        colnames(tibb_merge) <- c("Region", "Basin_ID", "Basin", "Year", "Mean Temperature", "Min Temperature", "Max Temperature", "Mean Precipitation", "Runoff coefficient")
        runoff_tmp_annual_list[[i]] <- tibb_merge
      }
      
      runoff_rate_tibble <- tib_basin_runoff_rates %>% left_join(., temperature_tibb, "Basin_ID") %>% .[,c(1:3, 12,4, 6, 9, 8)] #For each basin, a summary table for all the period
      runoff_rate_tibble <- runoff_rate_tibble %>% mutate(Mean_pcp = round(Mean_pcp,0), means = round(means, 2), Runoff_rate = round(Runoff_rate,2),
                                                         min_runoff_rate = round(min_runoff_rate,2), Max_runoff_rate = round(Max_runoff_rate,2))
      colnames(runoff_rate_tibble) <- c("Region", "Basin_ID", "Basin", "Mean Temperature", "Mean Precipitation", "Mean Runoff coefficient", "Min Runoff coefficient", "Max Runoff coefficient")
      
runoff_reg_tab <- runoff_rate_tibble %>% mutate(Region = factor(Region, levels = c("IMP", "CRB", "DTAL", "DTBJ", "MIX"))) %>% group_by(Region) %>% summarise(`Mean Temperature` = round(mean(`Mean Temperature`), 2), `Mean Precipitation` = round(mean(`Mean Precipitation`),0), `Mean Runoff ratte` = round(mean(`Mean Runoff coefficient`), 3), `Min Runoff coefficient` = round(min(`Mean Runoff coefficient`), 3), `Max Runoff coefficient` = round(max(`Mean Runoff coefficient`), 3), `Mean Runoff coefficient` = `Mean Runoff ratte`) %>% .[,c(1,2,3,7,5,6)] 

 apa(runoff_reg_tab)%>% tab_footnote("")

```

The influence of the lithology is highlighted when aggregating at region scale. For example, although temperature is slightly higher and precipitation is slightly lower in the high permeability detrital region, its runoff coefficient doubles the runoff coefficient of the low permeability region. Runoff coefficient is higher in the IMP and CRB regions, where not only precipitation and temperature are more favorable for generating runoff, but also lithology and the mountainous topography. Regions DTAL and DTBJ are flatter and warmer than the CRB region, and evapotranspiration is favored under these conditions [@custodio_hidrologisubterranea_1983]. It should be noted the subbasins selected in CRB region are closely located (@fig-location), thus they have a similar climate. Therefore, the runoff coefficient varies less than in the IMP region, where subbasin 3 is located in a more arid region than subbasins 1 and 2. Regardless this, the CRB region seems to be less influenced by climate than IMP region, which could be explained by its aquifer properties, allowing a higher recharge thus limiting the amount of water available for evapotranspiration. In DTAL and DTBJ regions, runoff coefficient its always lower than 10% (even 4% in DTBJ), which indicates that most of the precipitation becomes evapotranspirated. Even though some areas of the DTBJ region subbasins are conformed by medium permeability carbonate and detrital materials, runoff coefficient in this region is much lower than in DTAL, which points to a high influence of the presence of low permeability materials, which in combination with a flat topography, low precipitation and warmer temperatures lead to a very high evapotranspiration. Precisely due to the flat topography, it should be also acknowledged the possibility that a small amount of the recharged water might be released to the streamflow downstream the gauging points, but it is not expected to be a significant amount since the subbasins selected are relatively large.

Subbasins with mixed lithology yielded the widest range of runoff coefficient values, which could be expected. In line with the results discussed above, mixed lithology subbasins where igneous, metamorphic or carbonated materials dominate showed higher runoff coefficients, while the lowest values were obtained in those mixed subbasins where detrital materials with low permeability are present (e.g., subbasin 17, Appendix 2).

#### 4.2. Baseflow index values

@tbl-reg_alphas summarizes at region scale the *alpha* values obtained for each subbasin, their standard variation and the determination coefficients obtained during its calculation.

```{r alpha_values}
#| eval: true
#| echo: false
#| output: true
#| label: tbl-reg_alphas
#| tbl-cap: Results at region scale of the groundwater recession curves linear adjustment

 
alphas_tibble <- read.csv("used_files/Created_csv/3_alpha_estimation.csv") %>% 
mutate(regions = factor(regions, levels = c("IMP", "CRB", "DTAL", "DTBJ", "MIX")))
            
regions <-  factor(basins_file$region, levels = c("IMP", "CRB", "DTAL", "DTBJ", "MIX"))
         
   
tab <- alphas_tibble %>% group_by(Basins) %>% summarise(alpha_bas = mean(alphas), dcoef_bas = mean(det_coefs)) %>% cbind(regions) %>%  group_by(regions)   %>%  summarise(alpha_reg = round(mean(alpha_bas), 3), alpha_sd = round(sd(alpha_bas), 3), det_coef_reg = round(mean(dcoef_bas), 3)) 
colnames(tab) <- c("Region", "Mean alpha value", "Alpha standard deviation", "Mean determination coefficient")
  
apa(tab)%>% tab_footnote("")
  
```

It should be reminded that *alpha* in this baseflow filter is not the classical recession constant (α), and when *alpha* approximates to 1, α approximates to 0. Besides, when α tends to 0, it becomes close to $1-alpha$, considering the Taylor development of the @eq-gw_recession. The obtained *alpha* values showed relevant differences in the immediacy of baseflow response. The lowest value was obtained for the carbonate (CRB) region, which is expected considering its hydrogeological behavior (i.e., relevant karst aquifers with fractures, where recharge and release events response quickly to precipitation events and with enough storage capacity to maintain the streamflow during dry season). It also matches with a larger baseflow index expected, as mentioned above.

Considering the lithology, the highest alpha value would have been expected for the impervious region (IMP), since barely any baseflow response is expected there. However, the obtained value was not significantly different from other regions in the basin (@tbl-reg_alphas). Most probably, consecutive precipitation events in these subbasins and snowmelt processes could be maintaining a baseflow level which is not a result of groundwater contribution, and thus hindering recession constant calculation.

Regarding the detrital regions, the high permeability one showed the highest alpha value. The porosity of the high permeability materials, despite being higher than the materials of the CRB region, does not have fractures, which could have led to a slower recession response. The low permeability detrital region (DTBJ) showed an alpha value similar to the DTAL region, instead of being higher (thus less sensitive), as it would be expected. However, as mentioned before, the subbasins selected for the DTBJ region do not only consist of materials with low permeability, complicating results comparison. In fact, the DTBJ region seems to have a relevant contribution of baseflow, and its response to precipitation events seems to be slow (which can be explained to a low transmissivity derived from the low permeability materials). A graphical comparison of the hydrographs for one hydrological year (October-September) among subbasins located in the different geological regions is included in Appendix III, allowing to visualize some of the previous insights.

Once the three *alpha* values were obtained for each basin, a range of potential *alpha* values was estimated. Different values within this range were used for running the filter, in order to obtain a realistic separation of the hydrograph components. The values of *BFImax* were based both in the recommended values and in the expert knowledge of each basin, and the baseflow index was calculated for the entire period with @eq-bf_contribution. The results obtained through this methodology are highly influenced by the parameters used (specially *BFImax*), and therefore it is a subjective methodology. However, it is a useful tool that, used based on expert knowledge criterion, helps to estimate the relevance of groundwater contribution to the streamflow, thus further aiding in eventual soft calibration procedures.

After using this methodology, authors want to highlight some considerations or advises in order to help other modelers.

First, regarding the filter parameters, although *alpha* has been calculated from real hydrographs and *BFImax* values are recommended in literature, the values of the parameters must be settled by the user considering the basin characteristics. The influence that some factors (such as snowmelt or precipitations during the recession curve) have on the *alpha* value calculation should be considered. Therefore, the obtained *alpha* average does not necessarily have to be the used value, and it can be modified depending on factors such as the mentioned. Regarding the *BFImax* parameter, which will influence in a major extent the result obtained, should be adjusted carefully after reviewing the basin lithology and the characteristics of the peaks (e.g., recession curves during first months of the year could be also altered by snowmelt, which can suppose most of the baseflow in regions with snow processes, particularly if they are impervious). Adjustment of this parameter has been subjective in some subbasins with an impervious lithology (e.g., Basin 1, Navaluenga), as looking at the hydrograph, groundwater contribution should not be neglected despite presumably being impervious [@martin-loeches_hydrogeochemistry_2020]. As @fig-parameters_effect shows, both parameters are sensitive to the baseflow separation, and a realistic baseflow separation has been prioritized rather than using the calculated or recommended parameter values for *alpha* and *BFImax*.

Another consideration is about the data reliability. When applying the filter, the total value of streamflow in one day affects to the baseflow calculation in the next days. Therefore, if an anomalous value of streamflow is recorded (i.e., a very low value among a higher values series), we recommended to manually change this value to calculate the baseflow in a realistic way. Luckily enough, data used for this work have little anomalous values, and therefore, after examining them, a clean process was not considered necessary.

In this case, a configuration of the baseflow parameters suitable for three different peaks has been searched, because looking at only one event could have led to a non representative value of baseflow contribution. A correct approximation for three different events has been preferred than a perfect hydrograph separation for only one peak, as it provides confidence regarding the acceptability of the chosen parameter values. However, it should be acknowledged that this method might not allow to achieve a completely realistic separation (e.g., baseflow underestimated during long low flows periods and overestimated when precipitation events occur, @fig-bfsep_example) and therefore, an intermediate solution must be found to compensate for these inaccuracies. These limitations have been reported by other authors [@kang_baseflow_2022], and should be kept in mind when applying digital filters.

Last consideration is about the time scale used to evaluate the separation of the hydrograph components, which also justifies validating the filter separation in three different peaks. Looking at the separation of the hydrograph components for a longer time series including several peaks might lead to a visual perception of a larger amount of groundwater contribution, but looking for individual events allow to conserve the scale and perform properly the separation. @fig-timescale_effect compares how a peak is represented when looking at it inside the entire time series and when looking at it individually.

![Time scale effect on the visualization of the baseflow estimated with the filter.](figs/bfi_filter_timescale_ed.png){#fig-timescale_effect}

Following these considerations, the baseflow contribution for each of the basin has been calculated with @eq-bf_contribution. Appendix IV contains the values of the parameters used and the baseflow contribution values obtained for each of the subbasins. To assess the lithology effect, the estimated contribution values have been aggregated at geological region level as showed in @tbl-reg_gw_results.

```{r Groundwater_regions}
#| eval: true
#| echo: false
#| output: true
#| label: tbl-reg_gw_results
#| tbl-cap:

 read.csv("used_files/Created_csv/4_groundwater_results.csv") %>% .[,c(2,1,3,4,5,6)]%>% 
  mutate(Region = factor(region, levels = c("IMP", "CRB", "DTAL", "DTBJ", "MIX"))) %>% group_by(Region) %>% summarise('Mean alpha used' = round(mean(alpha), 3), 'Mean BFImax used' = round(mean(BFImax), 2),'Estimated baseflow index' = round(mean(BF_Rate), 2)) %>% apa(.) %>% tab_footnote("")

```

Subbasins located in geological regions with low permeability were expected to have lower baseflow index, while those located in regions with relevant aquifers were expected to have higher rates. A baseflow index around 20% has been estimated for the igneous and metamorphic region (IMP). This value might be considered high for impervious basins, but based in the knowledge about the studied subbasins and the assessment performed, it seems correct. Some indicators, such as the presence of flow during dry periods or phreatophyte vegetation can be used as indicators of groundwater contribution, and these indicators has been observed in some of the subbasins characterized as impervious in this work [@martin-loeches_hydrogeochemistry_2020].

As expected, the carbonate region (CRB) showed the highest baseflow index: it is dominated by a carbonate geology with karst processes and is climate its colder and more humid. Around 50% of the streamflow has been estimated as groundwater contribution, which matches with previous studies [@sanchez-gomez_optimization_2022] and it might be a realistic value taking into account the region properties. This rate is higher in some of the studied subbasins, e.g., subbasin 6, where a 57% percent of groundwater contribution has been estimated (Appendix IV).

Regarding the two detrital regions, despite their different permeability, the obtained values of groundwater contribution were close, slightly larger in the high permeability region (DTAL). As mentioned in the Methodology (section 3.1), this could be because the subbasins considered as representative of the low permeability detrital region (DTBJ) are constituted by mixed materials (with relevant areas of carbonate and detrital materials with medium and high permeability). Precipitation is low in the sector of the Tagus River basin where these two detrital regions are located, with lower altitudes and a flatter landscape. However, runoff coefficients obtained for DTBJ region are noticeable lower than in DTAL region, pointing to a very high evapotranspiration, and reducing in consequence the total streamflow. Baseflow index in the DTBJ region might be higher than expected, since in their permeable areas a fraction of water percolates (becoming recharge and thus less exposed to evapotranspiration). The hydrographs of the subbasins within the DTBJ region reveal this behavior, since a baseflow is maintained throughout the year (Appendix 3). On the contrary, in the low permeability areas, percolation is reduced and water is therefore highly exposed to evapotranspiration. Actually, the differences in the hydrological behavior in the defined detrital regions become more evident when comparing the runoff coefficient than when comparing the baseflow index, as already discussed.

In the subbasins located in mixed lithology regions, the baseflow index obtained in average is around 46%, thus relatively high. It could be explained because four of these subbasins (subbasins 16 to 19, Appendix 4) are constituted in a greater extent by carbonate materials, from medium to very high permeability (@fig-location), while only two of these subbasins have impervious igneous and metamorphic materials.

### 5. Conclusions

This work presents a reproducible methodology to collect soft data in a certain basin or group of basins, which can aid soft calibration of hydrological models, among other utilities. Two rates that help to characterize the hydrological behavior of a basin can be derived: the runoff coefficient and the baseflow index. The used software are QGIS and R, both open-source and with a collaborative philosophy, being available for the reader all the data and code used for reproducing this work.

Trough this methodology, the runoff coefficient can be automatically calculated for several basins, using as input data two vector layers: one with the delineation of the basins that will be assessed, and other with the grid of weather data that will be used. The Methodology section contains all the information to delineate the basins and to create the files used.

The baseflow index is estimated using a digital baseflow filter. It uses two parameters that should be adjusted considering the basin characteristics. The manuscript guides the modeler to guarantee a realistic and successful application of the filter, explaining how to estimate one of the filter parameters (*alpha*) from the groundwater recession curve. The adjustment of the estimated baseflow for different events was analyzed to provide an example and guidance about its use.

To demonstrate the usefulness of this methodology, a multi-spatial hydrological assessment has been performed in the upper sector of the Tagus River basin. High resolution gridded precipitation data and recorded streamflow data were used to calculate the runoff coefficient and the baseflow index in 19 drainage subbasins belonging to 5 different geological regions. Besides testing the methodology, which is the aim of the manuscript, the work done led to gain some new insights about the hydrological properties of the basin or confirm results from previous studies: groundwater in some regions which are considered impervious could be around 20%, evaporation can reach values higher than 95% in dry and warm years in certain areas, or that groundwater contribution is around 50% in regions with aquifer properties. Based on these results, further work could include improving the baseflow filter function or evaluating the runoff coefficient variation depending on different factors.

The soft data collected with this methodology can be used to guide a soft calibration process of any hydrological model, which in combination with a subsequent hard calibration process might allow to get a robust model that realistically represents the hydrological processes of a basin. In the study case presented, the noticeable differences obtained within the geological regions proves the usefulness of those steps prior to hard calibration. Therefore, the methodology presented in this manuscript might contribute to aid towards realistic studies in the hydrological modelling community, particularly in those areas with relevant climatic or geological heterogeneity.

### Data availability

All the data and code used for this work is available in the following GitHub repository: https://github.com/alejandrosgz/Soft_data_collection_methodology.git.

### Ackowledgements

Alejandro SÃ¡nchez-GÃ³mez received support from the University of AlcalÃ¡ (UAH) PhD Fellowships Program. Other projects?

Some of the used functions in R were written by other researchers. Concretely, in addition to the used packages (cited in References section), the baseflow filter function was written by Hendrik Rathjens, and the tables format function was taken from https://www.anthonyschmidt.co/post/2020-06-03-making-apa-tables-with-gt/.

Authors want to thank to AEMET for the gridded weather datasets and to the Water Resources Management and Planning Research Group (and particularly Dr. Javier Senent Aparicio) from the Catholic University of Murcia for adapting the weather datasets format and make it available (https://swat.tamu.edu/data/spain/).

### References

::: {#refs}
:::

######## Appendix I: Subbasins data {.appendix}

```{r}
#| eval: true
#| echo: false
#| output: false

  apa <- function(x, title = " ") {
  gt(x) %>%
    tab_options(
      table.border.top.color = "white",
      heading.title.font.size = px(16),
      table.font.size = px(14),
      column_labels.border.top.width = 3,
      column_labels.border.top.color = "black",
      column_labels.border.bottom.width = 3,
      column_labels.border.bottom.color = "black",
      table_body.border.bottom.color = "black",
      table.border.bottom.color = "white",
      table.width = pct(100),
      table.background.color = "white"
    ) %>%
    cols_align(align="center") %>%
    tab_style(
      style = list(
        cell_borders(
          sides = c("top", "bottom"),
          color = "white",
          weight = px(0.005)
        ),
        cell_text(
          align="center"
        ),
        cell_fill(color = "white", alpha = NULL)
      ),
      locations = cells_body(
        columns = everything(),
        rows = everything()
      )
    ) %>%
    #title setup
    tab_header(
      title = html(title)  # html("<i>", title, "</i>")
    ) %>%
    opt_align_table_header(align = "left")
}
```

```{r csv_file_basins}
#| eval: true
#| echo: false
#| output: true
# label: tbl-app_subbasins_data
#| tbl-cap: Selected subbasins properties and data availability

#Checking the available gauging data dates: 
data_range <- gauging_data_tagus %>% filter(cod %in% cods) %>% mutate(gauging_code = cod) %>% 
     group_by(gauging_code) %>% summarise(mindat=min(date), maxdat = max(date)) %>% 
     left_join(., basins_file[,c(1:2,4)], by =  "gauging_code") %>% arrange(., Basin_ID) %>% 
     mutate(`Streamflow data availability` = paste(year(mindat), year(maxdat), sep =  "-")) %>% 
     .[,c(1,6)]

#Checking if data is complete for the entire period (2010-2018)
ini <-  as.Date("2010/01/01")
end <-  as.Date("2018/12/31")
ndys <- seq(ini, end, 1) %>% length(.)

complete_data <- gauging_data_tagus %>% filter(cod %in% cods, year(date) %in% 2010:2018) %>%
   mutate(gauging_code = cod) %>% left_join(., basins_file, "gauging_code") %>% 
   group_by(gauging_code) %>% summarise( ndays = n()) %>% 
   mutate('Complete data (2010-2018)' =  case_when(ndays == ndys ~ "Yes", 
   ndays < ndys ~ paste("No, ", ndys-ndays, " days missing", sep = "")))
  
# Creating summary table
read.csv("used_files/Created_csv/1_basins_file.csv") %>% left_join(., data_range, "gauging_code") %>% 
  left_join(., complete_data, "gauging_code") %>% mutate(`Area (sq. km)` = round(area/1e6), 
  Region = region, `ID, subbasin and streamflow station code` = paste(Basin_ID, ", ", Basin, " (", gauging_code, ")", sep = "")) %>%
  .[,c(11,10,9,6,8)] %>% apa(., "Selected subbasins properties and data availability")
```

######## Appendix II: Runoff coefficients obtained for subbasins {.appendix}

```{r Runoff_rate_basins}
#| eval: true
#| echo: false
#| output: true
# label: tbl-runoff_rates
#| tbl-cap: Basins runoff coefficients. Average, minimum and maximum value for the entire period

 runoff_tmp_annual_list <- list() #For each basin, a list for the annual values
      for(i in 1:length(tmp_bas_list)){
        tmp <- tibble(tmp_bas_list[[i]])
        runoff <- tibble(anual_runoff_rate[[i]])
        tibb_merge <- left_join(tmp, runoff, "Year") %>% left_join(., basins_file[,c(1,2,5)], "Basin_ID") %>% .[,c(10,5,9,1,4,2,3,6,8)]
        colnames(tibb_merge) <- c("Region", "Basin_ID", "Basin", "Year", "Mean Temperature", "Min Temperature", "Max Temperature", "Mean Precipitation", "Runoff coefficient")
        runoff_tmp_annual_list[[i]] <- tibb_merge
      }
      
      runoff_rate_tibble <- tib_basin_runoff_rates %>% left_join(., temperature_tibb, "Basin_ID") %>% .[,c(1:3, 12,4, 6, 9, 8)] #For each basin, a summary table for all the period
      runoff_rate_tibble <- runoff_rate_tibble %>% mutate(Mean_pcp = round(Mean_pcp,0), means = round(means, 2), Runoff_rate = round(Runoff_rate,2),
                                                         min_runoff_rate = round(min_runoff_rate,2), Max_runoff_rate = round(Max_runoff_rate,2))
      colnames(runoff_rate_tibble) <- c("Region", "Basin_ID", "Basin", "Mean Temperature", "Mean Precipitation", "Mean Runoff coefficient", "Min Runoff coefficient", "Max Runoff coefficient")
      
      apa(runoff_rate_tibble, "Basins runoff coefficients. Average, minimum and maximum value for the entire period")%>% tab_footnote("")
      
```

######## Appendix III: Hydrographs for one hydrological year comparison {.appendix}

![Hydrographs comparison of subbasins located in the different geological regions.](figs/hydrographs.png){#fig-hydrographs}

######## Appendix IV: Groundwater results at subbasins scale {.appendix}

```{r Groundwater_basins}
#| eval: true
#| echo: false
#| output: true
#| label: tbl-groundwater_results
#| tbl-cap: Filter parameters values and estimated baseflow index for each basin

gw_file <- read.csv("used_files/Created_csv/4_groundwater_results.csv") %>% .[,c(2,1,3,4,5,6)]

colnames(gw_file) <- c("Subbasin ID","Subbasin","Region","alpha used", "BFImax used", "Estimated baseflow index")
 apa(gw_file, "Filter parameters values and estimated baseflow index for each basin")%>% tab_footnote("")

```
